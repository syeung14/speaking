## https://www.youtube.com/watch?v=PsLaI4jDftA

- Anytime that you're interacting with another person
who has their own interests and is trying to achieve their own ends,
they are trying to do the best they can, given what they want;
you're trying to do the best you can,
given what you want, and so you're interacting in a strategic situation.
'Game theory' is a mathematical theory
that attempts to make sense of how it is
that people interact in these strategic situations.

- John von Neumann wrote a very important book called the "Theory of Games"
with a guy named Oskar Morgenstern.
And in there, he `laid out` game theory.
And game theory is:
"The study of decision-making under conditions of uncertainty over time."

- It was originally developed in economics
in order to try and understand economic behavior, like why people buy certain things
or why they're willing to work for certain wages.
But later on, it was expanded and applied to a variety of different situations,
including biology, international relations,
and even interpersonal relations like friendship and parenting and family relations.

One of the things that game theory has really shown us, through recent study,
has been interactions that we `oftentimes` think as 'zero-sum,' or competitive,
are not as competitive as they seem.

In situations like in the Cold War, which most people thought,
that's gotta be a zero-sum game if anything is,
we discovered that actually there were opportunities for mutual cooperation.
Arms reduction treaties are a great example.
The U.S. and the USSR figured out
that if they could find a way to cooperate,
they could both save an enormous amount of money and effort
by reducing the number of weapons that they had.
Reagan and Gorbachev negotiated the START Treaty with one another,
and one of the big problems that they had is, how can you be sure
that while you're eliminating nuclear weapons,
your `adversary` is also eliminating nuclear weapons?

So rather than saying,
"We're just gonna get rid of some large percentage of our nuclear weapons and hope
that the USSR would do so as well,"
they `broke up` the interaction into a bunch of little tiny ones.
So, the USSR would eliminate just a few nuclear weapons,
then the U.S. `would eliminate` just a few nuclear weapons.
They would check, and then `they would go on to` the next stage.
And then each would eliminate a few more, and they'd go on to the next stage.
This process of taking a big interaction and breaking it down into little small parts
can change a bad social dilemma into a positive interaction.
What I do in my personal life and I think almost everyone can do in their personal life,
is to try and think, 
'In this interaction, `what outcome would be good` for both parties?'
And, 'How can we achieve that outcome?'
And by thinking about everything in that way, we oftentimes transform something that seems
like a situation where there has to be a winner and there has to be a loser,
`into one where` nobody `feels like` they've lost and everybody benefits.

- John von Neumann-based game theory `on a stripped down` version of poker.  [strip down = to take off clothes]
- In any given poker situation that you're dealing with a lot of uncertainty
and it's all about how to make the best decision in any given moment-and that's so `integral` to life.
Everything we try to do, you know, 'Should we take this route or that route?'
'Should I go here on vacation or there?'
It's all about `dealing with uncertainties and probabilities of things` happening-
and poker is a very fun and easy way to teach someone how to do that.

First rule of thumb is `how to extract the most money`
or `chips` from your opponent when you have a strong hand and how to lose the minimum when you have a weak hand.
You're never going to be 100% certain where you are:
are you beating them or do you have a worse hand?
So, you have to sort of construct a strategy
that is mathematically optimal in each situation.

The most damaging bias that can come up in poker,
and I also think very often in life, is the 'Sunk cost fallacy.'
Where you'll have a lot of chips, perhaps almost all of your stack is in the middle,
and yet, you are 85% to 90% confident that you have the worst hand.
Putting another chip in the pot is probably not a good idea, but we'll often go to ourselves,
"Ah, well, I've gone this far. I've put this much in.
I might as well `see it through` to the end."
But if you have very strong information that actually, from this point onwards,
putting more money in the pot is a bad idea, then you shouldn't.
But we have this belief that,
"Well, I've put `this much time in` or this much effort,
that we should continue on."
That can be very, very costly.

Once you start paying attention to the sunk cost fallacy, once it's on your radar,
you'll probably notice at least a few things
that you wish you were doing differently.
Those might be small-scale.
In my case, I'm now much more willing to abandon a book
that I've realized I'm not enjoying
and not getting any value out of, rather than `trudging dutifully` through the remainder 
   [trudge=to walk or march steadily and usually laboriously; dutiful=filled with motivation]
of the book just because I've already come 100 pages.

These changes might also be large-scale. For example, I was in a Ph.D. program,
and, at a certain point, realized with increasing certainty that I wasn't happy in this field,
and `would probably be better off` switching.
And that the only reason that I had stuck with it as long as I had 
was because of my fear of confronting the `sunk cost` of four to five years
that I'd spent preparing for and working in the Ph.D.

And sometimes it really does take time to `fully acknowledge to yourself`
that you don't have any good reason to stick with the job or Ph.D.
or `project that` you've been working on so long because sunk costs are painful.
But at least having the sunk cost fallacy `on your radar`
means that you have the opportunity, at least,
`to push past that` and make the choice that instead will lead to the better outcomes for your future.

- Game theory spent much of its early days analyzing zero-sum games,
where one party's gonna win and the other party's gonna lose
to trying to figure out what's the best strategy.
What game theorists have figured out is that in zero-sum games,
the best strategy to pursue when you're against
a sophisticated opponent is to `adopt` the strategy which `minimizes your maximum loss`.
This is sometimes called the 'Minimax strategy.'

So the idea is you think,
"What's the worst-case scenario for me?
What could my opponent do that would make me worse off?"
And then you figure out, "What's the best strategy against that?"
So you're minimizing your maximum loss.
Game theorists proved that if you use this way of thinking,
minimizing your maximum loss, you ensure that,
no matter how sophisticated your opponent is,
`you've guarded against` the worst-case scenario.
And not only that, but in zero-sum games,
you've done the best you can possibly do.

- Get smarter, faster with videos
from the world's biggest thinkers.
To learn even more from the world's biggest thinkers,
get Big Think+ for your business.